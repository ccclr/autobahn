# Copyright(C) Facebook, Inc. and its affiliates.
from fabric import task, Connection
import time
import numpy as np

from benchmark.local import LocalBench
from benchmark.logs import ParseError, LogParser
from benchmark.utils import Print
from benchmark.plot import Ploter, PlotError
from benchmark.gcp_instance import InstanceManager
from benchmark.remote import Bench, BenchError
from paramiko import RSAKey


@task
def local(ctx, debug=True):
    ''' Run benchmarks on localhost '''
    bench_params = {
        'faults': 0, 
        'nodes': 4,
        'workers': 1,
        'rate': 100000,
        'tx_size': 512,
        'duration': 20,

        # Unused
        'simulate_partition': True,
        'partition_start': 5,
        'partition_duration': 5,
        'partition_nodes': 1,
    }
    node_params = {
        'timeout_delay': 1_000,  # ms
        'header_size': 32,  # bytes
        'max_header_delay': 200,  # ms
        'gc_depth': 50,  # rounds
        'sync_retry_delay': 1_000,  # ms
        'sync_retry_nodes': 4,  # number of nodes
        'batch_size': 500_000,  # bytes
        'max_batch_delay': 200,  # ms
        'use_optimistic_tips': False,
        'use_parallel_proposals': True,
        'k': 1,
        'use_fast_path': True,
        'fast_path_timeout': 200,
        'use_ride_share': False,
        'car_timeout': 2000,

        'simulate_asynchrony': True,
        'asynchrony_type': [3],

        'asynchrony_start': [10_000], #ms
        'asynchrony_duration': [20_000], #ms
        'affected_nodes': [2],
        'egress_penalty': 50, #ms

        'use_fast_sync': True,
        'use_exponential_timeouts': True,
    }
    try:
        ret = LocalBench(bench_params, node_params).run(debug)
        print(ret.result())
    except BenchError as e:
        Print.error(e)


@task
def create(ctx, nodes=1):
    ''' Create a testbed'''
    try:
        InstanceManager.make().create_instances(nodes)
    except BenchError as e:
        Print.error(e)


@task
def destroy(ctx):
    ''' Destroy the testbed '''
    try:
        InstanceManager.make().terminate_instances()
    except BenchError as e:
        Print.error(e)


@task
def start(ctx, max=4):
    ''' Start at most `max` machines per data center '''
    try:
        InstanceManager.make().start_instances(max)
    except BenchError as e:
        Print.error(e)


@task
def stop(ctx):
    ''' Stop all machines '''
    try:
        InstanceManager.make().stop_instances()
    except BenchError as e:
        Print.error(e)


@task
def info(ctx):
    ''' Display connect information about all the available machines '''
    try:
        InstanceManager.make().print_info()
    except BenchError as e:
        Print.error(e)


@task
def install(ctx):
    ''' Install the codebase on all machines '''
    try:
        Bench(ctx).install()
    except BenchError as e:
        Print.error(e)


@task
def remote(ctx, debug=True):
    ''' Run benchmarks on AWS '''
    bench_params = {
        'faults': 0,
        'nodes': [4],
        'workers': 1,
        'co-locate': True,
        'rate': [100_000],
        'tx_size': 512,
        'duration': 60,
        'runs': 1,

        # Unused
        'simulate_partition': True,
        'partition_start': 5,
        'partition_duration': 5,
        'partition_nodes': 1,
    }
    node_params = {
        'timeout_delay': 1_000,  # ms
        'header_size': 32,  # bytes
        'max_header_delay': 200,  # ms
        'gc_depth': 50,  # rounds
        'sync_retry_delay': 1_000,  # ms
        'sync_retry_nodes': 4,  # number of nodes
        'batch_size': 500_000,  # bytes
        'max_batch_delay': 200,  # ms
        'use_optimistic_tips': False,
        'use_parallel_proposals': True,
        'k': 1,
        'use_fast_path': True,
        'fast_path_timeout': 200,
        'use_ride_share': False,
        'car_timeout': 2000,

        'simulate_asynchrony': True,
        'asynchrony_type': [3],

        'asynchrony_start': [10_000], #ms
        'asynchrony_duration': [20_000], #ms
        'affected_nodes': [2],
        'egress_penalty': 50, #ms

        'use_fast_sync': True,
        'use_exponential_timeouts': True,
    }
    try:
        Bench(ctx).run(bench_params, node_params, debug)
    except BenchError as e:
        Print.error(e)


@task
def plot(ctx):
    ''' Plot performance using the logs generated by "fab remote" '''
    plot_params = {
        'faults': [0],
        'nodes': [4],
        'workers': [1, 4, 7, 10],
        'collocate': True,
        'tx_size': 512,
        'max_latency': [2_000, 2_500]
    }
    try:
        Ploter.plot(plot_params)
    except PlotError as e:
        Print.error(BenchError('Failed to plot performance', e))


@task
def kill(ctx):
    ''' Stop execution on all machines '''
    try:
        Bench(ctx).kill()
    except BenchError as e:
        Print.error(e)


@task
def logs(ctx):
    ''' Print a summary of the logs '''
    try:
        print(LogParser.process('./logs', faults='?').result())
    except ParseError as e:
        Print.error(BenchError('Failed to parse logs', e))


@task
def latency(ctx):
    """
    Measure SSH latency (ms) between all nodes in nodes.txt
    """
    from benchmark.gcp_instance import InstanceManager

    manager = InstanceManager.make()
    settings = manager.settings
    try:
        ctx.connect_kwargs.pkey = RSAKey.from_private_key_file("/home/ccclr0302/.ssh/google_compute_engine")
        connect_kwargs = ctx.connect_kwargs
    except (IOError, PasswordRequiredException, SSHException) as e:
        Print.error(f"Failed to load SSH key: {e}")
        return

    with open("nodes.txt") as f:
        nodes = [line.strip() for line in f if line.strip()]
    m = len(nodes)
    latency_matrix = np.zeros((m, m))

    def ssh_latency(src, dst, repeat=3):
        if src == dst:
            return 0.0
        results = []
        for _ in range(repeat):
            try:
                conn = Connection(host=dst, user=settings.username, connect_kwargs=connect_kwargs)

                conn.run("echo warmup", hide=True, timeout=5)
                
                start = time.time()
                conn.run("echo hello", hide=True, timeout=5)
                end = time.time()
                
                conn.close()
                results.append((end - start) * 1000)
            except Exception as e:
                print(f"Error SSH {src} → {dst}: {e}")
                results.append(np.nan)
        # 只要有一次成功就取成功的平均，否则为nan
        valid = [x for x in results if not np.isnan(x)]
        return np.mean(valid) if valid else np.nan

    for i, src in enumerate(nodes):
        for j, dst in enumerate(nodes):
            if i != j:
                latency_matrix[i][j] = ssh_latency(src, dst)

    print("SSH Latency Matrix (ms):")
    print(latency_matrix)

    # 计算指标
    def average_latency(L):
        vals = [L[i][j] for i in range(m) for j in range(m) if i != j and not np.isnan(L[i][j])]
        return np.mean(vals)

    def asymmetry(L):
        vals = [abs(L[i][j] - L[j][i]) / (L[i][j] + L[j][i])
                for i in range(m) for j in range(m)
                if i != j and not np.isnan(L[i][j]) and not np.isnan(L[j][i]) and (L[i][j] + L[j][i]) > 0]
        return np.mean(vals)

    mu = average_latency(latency_matrix)
    asym = asymmetry(latency_matrix)

    print(f"\nAverage SSH Latency: {mu:.2f} ms")
    print(f"Asymmetry Degree: {asym:.4f}")
